# -*- coding: utf-8 -*-
"""LogisticRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GEh79Sj_T-uq6E8XvHCFykxaSwLycfFU
"""

import pandas as pd
import numpy as np


class Logistic_Regression:
    def __init__(self, lr, iter):
        self.lr = lr
        self.iter = iter
        self.weight = None
        return

    def sigmoid(self, X):
        a = 1./(1.+np.exp(-1*np.dot(X, self.weight)))
        return a

    def classify(self, prob):
        if prob >= 0.5:
            return 1
        else:
            return -1

    def gradient(self, X, Y):
        grad_E = np.zeros(X.shape[1])
        for n in range(X.shape[0]):
            t_n = Y[n]
            X_n = X.iloc[n, :]
            y_n = self.sigmoid(X_n)
            # Gradient of Error function
            grad_E += (y_n-t_n)*X_n
        return grad_E

    def fit(self, X, Y):
        # Add a bias column of all 1s
        X["bias"] = 1
        # Initialize the weights to 0
        self.weight = np.ones(X.shape[1])
        # Run the gradient descent algorithm
        for i in range(self.iter):
            # Update the weight based on the gradient with the current weight vector
            self.weight -= self.lr*self.gradient(X, Y)
            # Count misclassifications
            misclassifications = 0
            # Print the misclassifications
            if i % 2 == 0:
                for j in range(X.shape[0]):
                    X_j = X.iloc[j, :]
                    Y_j = Y.iloc[j]
                    if self.classify(self.sigmoid(X_j)) != Y_j:
                        misclassifications += 1
                print(self.weight)
                print("misclassifications:")
                print(misclassifications)
                print("epochs:")
                print(i)
        return

    def predict(self, X):
        X["bias"] = 1
        prediction = []
        for i in range(X.shape[0]):
            X_i = X.iloc[i, :]
            prediction.append(self.classify(self.sigmoid(X_i)))
        return prediction


df = pd.read_csv("feature_engineering_2.csv")
df = df.dropna()
tr = df.iloc[:375, :]
test = df.iloc[375:, :]
y = tr.iloc[:, 1]
y_test = test.iloc[:, 1]

tr = tr.drop(tr.columns[[0, 1]], axis=1)
test = test.drop(test.columns[[0, 1]], axis=1)
y.replace('M', 1, inplace=True)
y.replace('B', -1, inplace=True)
y

test

tr

model = Logistic_Regression(0.001, 100)
model.fit(tr, y)
predicted = model.predict(test)


count = 0
for i in range(len(predicted)):
    if predicted[i] == y_test.iloc[i]:
        count += 1

print(predicted)
print(y_test)
print(count)
